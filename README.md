panda
=====

In Jenkins, one deals with jobs, their parameters, their orchestration, their duplication between branches (using templating or not), the duplication of their orchestration, etc. In the Jenkins core, not much of this is available. One would need to install plug-ins, update ones or even create some from scratch. And then make them work together.

My feeling is that the idea of a pipeline should be central to the continuous integration.

The idea behind `panda` (1) is to be able to support pipelines.

One would define a `pipeline` in Panda with a given set of parameters. It would be associated with `stages` that are run in sequence, automatically, manually or conditionally (using triggers).

Stages are groups of jobs that are either run in parallel or in sequence. Each job accepts a subset of the parameters defined by the pipeline. A job can be linked to a real (remote) Jenkins job, or be anything else.

A pipeline can be defined with a default set of parameters, but `branches` can be defined as other sets of parameters.

One can run a pipeline for a given branch or the default branch. The input parameters can be overridden if needed. The outcome of such a run is designed as a `(pipeline) instance`. This `instance` will go through each stage, running all the associated jobs.

A dashboard per pipeline and branch allows to see at one glance the status of the last instances. From there, one can triggers the next manual stages if available.

# Instance life-cycle

When an authorized user creates an instance for a pipeline, he has to select the branch he wants this instance for, and fill in parameters that are either required or allowed to be overridden.

Therefore, an instance is the association of the branch of a pipeline and a set of parameter values. The branch can also be the default one for the pipeline.

Before even starting its life, one instance can be associated with extra parameters. Those parameters are generated by _instance parameters contributors_ extensions. A typical example is the attribution of a _version_ parameter to the instance. This is such a classic example that such an extension is built-in in the core code.

Once the instance is fully parametrized, it is eligible for run.

An instance is eligible for run if:
* its set of parameters is complete
* it is not currently running

Once an instance is selected for run by the _instance runner_, the next available stage is computed and activated in the _stage runner_. All jobs defined by this stage are run, in parallel or in sequence, according the stage settings, by the _job runner_.

Once all the jobs are complete, the stage is marked as well as complete. The _status_ of the stage depends on all the _statuses_ of its jobs. Typically, a stage is marked as Success if all its jobs have also the Success status.

In the end, the instance is back into the instance runner and the subsequent stages can be activated.

Several points must be noted here:
* the creation of an instance can be triggered automatically (see _Triggers_)
* the first stage of an instance is always triggered automatically
* the subsequent stages of an instance are triggered according to the settings of the stage:
  * manual
  * automatic
  * custom trigger

Once all the stages of an instance have been run, the instance itself is marked as complete.

## Instance compatibility with the pipeline

Instances are created, run and completed. It may be important to keep their definition and their result for history and investigation reasons.

In the meantime, it is likely that the pipeline (i.e. the definition the instances are spawn from) will also be adapted: parameters, branches, stages, jobs...

How running, idle and completed instances should behave when their associated pipeline is adapted?

The general idea is that an instance, once spawned from a pipeline, is _almost_ independent of it.

At any time, instances are associated with:
* a set of parameters
* a branch
* a list of stages & jobs that have been run
* a current stage & a list of current jobs

When a decision has to be made, it is only about a _next stage_ to select. Only at this time do we need to refer to the pipeline definition. In any other case, for _past_ history, the instance can keep its state independently on the pipeline. This state is defined by copying the definition from the pipeline, and by not keeping any live reference to it.

If a pipeline defines stages A -> B -> C and an existing instance has already run A and B, when the pipeline manager removes the B stage, the instance keeps the fact that B has been run for it.

When an instance is selected by the instance runner to be run, the next stage to run may be impossible to compute because of an inconsistent state between the instance and the pipeline. In the previous example, the instance cannot run C after B, because the pipeline now defines only A -> C, without any reference to B. In such case, the instance would be marked as Complete and its status would be Inconsistent.

When an instance is complete, it retains for ever its complete state and its last status, independently of any change at pipeline level.

The only way that an instance may disappear completely is when the pipeline itself is removed. Such an operation has dramatic effects and is allowed only to administrators.

# Authorizations

Public access in read-only mode is generally granted in Panda, for all pipelines & associated instances. One user must be authenticated and granted with some authorizations before doing anything.

Main authorization levels are:
* Administrator -> can do anything
* Manager -> granted at pipeline level, can manage the definition of the pipeline (branches, parameters, states, jobs...)
* Executor -> granted at pipeline level, can trigger the creation of instances and their executions.
* Promoter -> granted at stage level, can trigger the execution of a stage for an existing instance

Note that automatic processes like triggers for instances or stages would always be executed with Executor rights.

---
(1) Probably a temporary name for this project... The idea came after a discussion - maybe an explanation could come later.
